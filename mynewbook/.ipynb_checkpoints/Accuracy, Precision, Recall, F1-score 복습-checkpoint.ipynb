{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1482e735-789e-4269-857e-c33eaaa4e150",
   "metadata": {},
   "source": [
    "# Accuracy, Precision, Recall, F1-score 복습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0db81b1-375f-4370-9654-5a024a2f5f23",
   "metadata": {},
   "source": [
    "서울과학기술대학교 데이터사이언스학과 홍정식 교수님의 데이터마이닝 수업 자료와 ‘[핸즈온 머신러닝](https://product.kyobobook.co.kr/detail/S000001810262)’을 참고하여 작성하였음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6645c794-e84f-4e48-b014-d6cc2a838b68",
   "metadata": {},
   "source": [
    "## 요약"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16505473-97cb-4e25-9097-ffd6a9b85892",
   "metadata": {},
   "source": [
    "![](images/metrics/confusion-table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c8fd13-2978-424c-94e8-6b23b17a20c3",
   "metadata": {},
   "source": [
    "$$\\text{Accuracy}=\\frac{TP + TN}{TP + FN + FP + TN}=\\frac{\\text{올바르게 분류}}{\\text{전체}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2f498-d5ce-4557-b0f9-75643592025e",
   "metadata": {},
   "source": [
    "$$\\text{Precision} =\\frac{TP}{TP + FP} = \\frac{\\text{예측1} \\cap \\text{실제1}}{예측1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad1df87-ccfb-40dd-b11d-784d1a1432ea",
   "metadata": {},
   "source": [
    "$$\\text{Recall} =\\frac{TP}{TP + FN} =\\frac{\\text{예측1} \\cap \\text{실제1}}{실제1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f378730-2b96-4d1d-9bd7-c75c51efa560",
   "metadata": {},
   "source": [
    "$$\\text{F1-Score} = \\text{Recall과 Precision의 조화평균}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda3da23-20e2-480b-86c2-02a10c2af91a",
   "metadata": {},
   "source": [
    "## 기본 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e9aa9a-fd8e-45d7-8afb-e85cd796e561",
   "metadata": {},
   "source": [
    "아래와 같은 BFP(body fat percentage)라는 데이터가 있다고 해보자. 이 데이터로 남성/여성 분류를 해보자."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5f69c9f-5ec0-4f68-a8f0-f93555bcdf0e",
   "metadata": {},
   "source": [
    "![](images/metrics/bpr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc94886-bf68-4235-a35c-701cfe2a1878",
   "metadata": {},
   "source": [
    "아주 아주 간단한 모델이 있다. 이 모델은 BFP가 20보다 높으면 여자, 낮으면 남자라고 분류했다고 하자. 나르샤, 류담, 정형돈이 잘못 분류되었고 나머지 사람들은 잘 분류되었다!\n",
    "\n",
    "그런데 20이라는 값으로 잘 나누었다고 할 수 있을까? 이 모델의 성능은 몇이라고 해야할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e8cc9-e343-4b6a-887c-98762fcc93c9",
   "metadata": {},
   "source": [
    "## Confusion matrix (혼동 행렬)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe97df1-a0a3-4990-b79c-8145716f2f91",
   "metadata": {},
   "source": [
    "Confusion matrix는 기계학습 분야에서 지도 학습으로 훈련된 분류 알고리즘의 성능을 시각화 할 수 있는 표이다. (위키피디아)\n",
    "\n",
    "분류 결과를 가지고 Confusion matrix를 그려보면 아래와 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a204010e-d73c-4fd0-ad3e-06b35c2bdcd9",
   "metadata": {},
   "source": [
    "![](images/metrics/confusion-matrix-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b3b18-8780-4677-970a-f2740da5ec47",
   "metadata": {},
   "source": [
    "Actual은 정답라벨을 의미하고, Predicted는 예측된 라벨을 의미한다. 위에서 얘기한 것처럼, 나르샤는 실제론 여자(F)인데 남자(M)로 분류되어 F행 M열에 위치해있고, 류담과 정형돈은 실제로는 남자(M)인데 여성(F)으로 분류되어 M행의 F열에 위치해있다. 나머지 칸은 올바르게 분류되었다.\n",
    "\n",
    "이 표를 좀 더 일반화해볼까? Confusion matrix를 기반으로 다음과 같은 지표들이 생성될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d54413-b84a-4c38-a538-5a42e478a687",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e773aa5a-bd13-45c5-b054-2c94a6ea9835",
   "metadata": {},
   "source": [
    "$$\\text{Accuracy}=\\frac{TP + TN}{TP + FN + FP + TN}=\\frac{\\text{올바르게 분류}}{\\text{전체}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecedff3-d180-4730-91e8-cd7e2190ff00",
   "metadata": {},
   "source": [
    "가장 직관적인 비율이다. 전체 데이터 샘플 중에서 올바르게 분류된 샘플의 수를 비율로 나타낸 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f679106a-e32b-4f7b-915f-3b7d17e23042",
   "metadata": {},
   "source": [
    "### Accuracy의 한계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e809e-1ad1-4ce6-b894-2b76a516a6a8",
   "metadata": {},
   "source": [
    "그런데 Accuracy는 데이터에 따라 잘못된 통계를 나타낼 수도 있다. 예를 들어 스팸메일이면 1, 정상 메일이 아니면 0이라고 예측하는 모델을 만들었다고 해보자.\n",
    "\n",
    "근데, 일반적으로 정상적인 메일이 대다수이고 스팸메일은 많은 비중을 차지하지 않는다. 예를 들어 정상 메일이 95개, 스팸메일이 5개라고 해보자. 그리고 이 모델이 스팸 메일을 1개밖에 걸러내지 못했고, 정상 메일 중에서 5개를 스팸 메일로 잘못 예측했다고 해보자. 그럼 Confusion matrix는 어떻게 될까?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10aa684e-2529-4b2f-afec-5a1bbc094e32",
   "metadata": {},
   "source": [
    "![](images/metrics/accuracy-draw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974aa170-b860-4ef8-922a-fa73cde3d7e8",
   "metadata": {},
   "source": [
    "여기서 Accuracy를 구해보면, 91/100=0.91, 무려 91%의 정확도를 가진 모델이 된다. 언뜻 보면 높아보이지만, 좋은 모델이라고 절대로 할 수 없다. 왜냐하면 데이터 Imbalance가 심하기 때문이다. 모두 정상 메일이라고 예측해도 95%가 나오기 때문에 Imbalance가 심한 데이터에서는 Accuracy를 신뢰할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe7bac-86bd-45f0-a668-2a785e59ba25",
   "metadata": {},
   "source": [
    "이처럼 클래스 분포 및 원하는 task에 따라 Recall, Precision, F1-Score등의 다양한 관점에서 성능을 측정해야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4005a39d-7f9e-4547-96a2-7fff6af92e2a",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08253494-c33c-4ee7-b877-5116c1d00a0c",
   "metadata": {},
   "source": [
    "‘재현율’이라고도 부르는 Recall의 수식은 다음과 같다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf7b84a-4e0a-4abc-b4b8-54dfc94eefd3",
   "metadata": {},
   "source": [
    "$$\\text{Recall} =\\frac{TP}{TP + FN} =\\frac{\\text{예측1} \\cap \\text{실제1}}{실제1}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7699cc6e-5cfb-4359-97ba-b7219e2e761f",
   "metadata": {},
   "source": [
    "\n",
    "![](images/metrics/recall-draw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b61b2d-be40-44d0-b253-9a0512ce922f",
   "metadata": {},
   "source": [
    "실제 1에 대한 (예측 1 ∩ 실제 1)의 비율이다. 위의 예시를 다시 보자. 실제 스팸메일이 5개 였는데(주황 박스) 이 중에서 1개만(파란 박스) 올바르게 예측했으므로 Recall은 1/5=0.2가 된다. Accuracy는 매우 높았는데 Recall은 매우 낮다. Accuracy만 보고 좋은 모델이라고 했으면 큰일 날 뻔했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74033905-5851-4b0e-bf74-af112ec5cc79",
   "metadata": {},
   "source": [
    "### Recall을 봐야 하는 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed698ed-91e6-42fd-aba3-ad21fa9ab0dc",
   "metadata": {},
   "source": [
    "예를 들어보자. 감시카메라로 좀도둑을 잡아내는 분류기를 학습시키고자 한다. 이 경우에는 좀도둑이라고 예측한 케이스가 많아도 상관없다. 못 잡아내는 단 1번이 너무 크리티컬하기 때문이다. 이 잡듯 여기저기 다 뒤져서라도 잡으면 그게 못 잡는 것보다 나은 경우이다. 그렇다면,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64885d32-8d39-41ae-adcc-9ef7d8440440",
   "metadata": {},
   "source": [
    "Recall( = (예측1 ∩ 실제1) / 실제1)이 중요할까? Precision( = (실제1 ∩ 예측1) / 예측1)이 중요할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5818e76-5119-4c7a-a09e-d2167d81e92f",
   "metadata": {},
   "source": [
    "Recall이 올라가려면 예측1이 많으면 많을수록 높아지긴 한다. 그러니까 Recall을 사용하는 경우는 예측1이 아무리 많아도 타격 없는, 1을 잡아내는게 너무나도 중요한 경우이다. 질병을 예측하는 일도 Recall 성능을 확인해야 할 것이다. 왜냐하면 일단 질병이라고 예측했는데, 아니더라도 큰 타격이 없기 때문이다. 그러나 이 질병을 맞추지 못한 경우에는 어마어마한 페널티가 따를 것이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "781c2db3-9ad8-413e-aadf-9c53273869f7",
   "metadata": {},
   "source": [
    "![](images/metrics/recall-draw-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882eb520-953d-4cbd-bc8f-94e02a290241",
   "metadata": {},
   "source": [
    "극단적으로(편하게) 생각하자면 Recall은 빈대 잡다가 초가삼간 다 태워도 괜찮다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed25edf-db76-4e86-9821-f822569000cd",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ff1fd-39ae-43f3-a54d-7a922142942a",
   "metadata": {},
   "source": [
    "만약 이 모델이 모든 메일을 스팸메일이라고 예측하는 아주 못된(?) 모델이라고 해보자. 그 때의 Confusion matrix는 다음과 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c2c54be-1179-4549-ba9b-478034fe0778",
   "metadata": {},
   "source": [
    "![](images/metrics/precision-draw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52476677-b77e-4a06-9e09-500fe3ea248a",
   "metadata": {},
   "source": [
    "이 경우에는, Accuracy = 5 / 100 = 0.05이고, Recall = 5 / 5 = 1이 나오게 된다. 아니 무려 Recall이 1이다. 왜 이런 일이 일어났는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b91368-b7d2-4e55-934d-f49d2b928296",
   "metadata": {},
   "source": [
    "Recall은 실제 1 중에서 예측 1이 얼만큼 채워졌는지 만을 보기 때문에 싹 다 1로 예측해버리면 Recall=1이다. 이런 상황에서는 Precision(정밀도)가 도움이 될 수 있다. Precision은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df935c-43cb-47d9-a06a-c946511c010b",
   "metadata": {},
   "source": [
    "$$\\text{Precision} =\\frac{TP}{TP + FP} = \\frac{\\text{예측1} \\cap \\text{실제1}}{예측1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a6e1b-c85a-44b6-8030-013d37dbd615",
   "metadata": {},
   "source": [
    "예측 1에 대한 (실제 1∩예측 1)의 비율."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445946b0-669e-422e-87a2-f91f971f54b7",
   "metadata": {},
   "source": [
    "예측을 1로 내놓은 것 중에서 실제 1이 얼마나 차지하는 지를 나타낸 것이다. 위의 예시에서 Precision을 계산해보면, Precision=5 / 100 = 0.05가 된다. 갑자기 왜 이렇게 낮아졌냐? 하면, 1로 예측한 것은 엄청 많은데, 그 중에 실제 1이 별로 없기 때문이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "738be4e9-30cf-431b-ba35-85012c26835f",
   "metadata": {},
   "source": [
    "![](images/metrics/precision-draw-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9f215a-904f-41bb-a5dd-f8de17a4cb3b",
   "metadata": {},
   "source": [
    "### Precision이 중요한 경우는?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e988e91a-2109-4678-a910-8440f2c9ea92",
   "metadata": {},
   "source": [
    "(실제 1∩ 예측 1 ) / 예측 1 가 의미하는 것은 뭘까? 1로 예측한 것 중에서 실제 1이 많이 들어있으면 된다. 그럼 예측1을 무작정 늘릴 수 없다. 차라리 확실하게 1인 것만 1로 예측하면 Precision은 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e6ffb-8ce8-4c1d-ac2a-47054e4ce55e",
   "metadata": {},
   "source": [
    "Precision이 높다? 이것은 모델이 모든 1을 잘 잡아낸다고 할 순 없어도, **1이라고 예측하면 거진 다 1이라는 것이다!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfa6fec-775a-4f15-b85a-12c2b55c8d30",
   "metadata": {},
   "source": [
    "내가 써 놓고도 너무 헷갈린다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e8682d-55e0-40cd-b9db-4a433a6ddec0",
   "metadata": {},
   "source": [
    "대표적 예시로 스팸메일 분류가 Precision 지표를 사용하면 좋다. 정상적인 메일까지 이 잡듯 뒤져서 분류할 필요는 없다. 대신에 스팸이라고 분류했으면, 진짜 스팸이기만 하면 만족스럽다. 실제로도 사용자는 스팸함에 잘 들어가지 않는다. 그래서 정상 메일이 하나라도 스팸함에 들어가면 이 서비스를 중단하고 싶어질 것이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d027a66-76e5-4fe8-9cf4-6ecdfafe8b67",
   "metadata": {},
   "source": [
    "![](images/metrics/precision-need.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf2ade0-ae16-4ec4-a372-1f8ead142635",
   "metadata": {},
   "source": [
    "# F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b78b61-a31b-4397-a412-4e1e76ffb4c0",
   "metadata": {},
   "source": [
    "지금까지를 요약해보면 이렇다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fccf2f-54de-4c4e-9f5b-1892f7f44c2c",
   "metadata": {},
   "source": [
    "실제 1 중에서 예측 1이 얼마나 차지하는가? → Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad5db9-3a5b-45b6-9e38-fe3fb05e44ba",
   "metadata": {},
   "source": [
    "예측 1 중에서 실제 1이 얼마나 차지하는가? → Precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79f7a9-a572-49f0-acc5-bf8211d13af7",
   "metadata": {},
   "source": [
    "둘 다 성능을 계산하는 지표로서 타당해 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95902a9-6ce3-4f08-9188-29da3c4e9086",
   "metadata": {},
   "source": [
    "Recall과 Precision을 F1-Score라는 하나의 숫자로 만들면 편리할 때가 많다. 특히 두 분류기를 비교할 때 좋다. F1-Score는 아래와 같이 Recall과 Precision의 조화 평균이다."
   ]
  },
  {
   "attachments": {
    "b4f4967e-9461-431b-aa93-9bdd4a20e8a0.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABBCAYAAADBo1/5AAAm9UlEQVR4Xu3dCcxt1/g/8CIooSoN\nEqXSFinV1BRtNVzEUCH4aQ25xU2VhrSNMcYYY6gYQxGUmPr/GUMRY+pFjDHGGFo3xtQUY4z/H+fX\nz/L7njx32ee85x3Ove977/4mT87Ze6+19lrPWuu7nvWstfc+6AUveMGEPPe5z5085znPGWWbiXob\nZZRRDjzB2+edd177xQXPetazJgc9//nPbyef/exnT573vOeNss1E/Y0yyigHpiD2pz/96ZNnPvOZ\nk6c+9amTg2Lp/eMf/5j8/e9/H2WbiXobZZRRDkz517/+Nfnzn//cyPxlL3vZvwmdpYcc/uf//88o\n20z++c9/jjLKKAeoAO7mdmGp/wehjxgxYsSI7QNW+jOe8YwmI6GPGDFixDbGSOgjRowYsZ9gJPQR\nI0aM2E8wEvqIESNG7CcYCX3EiBEj9hOMhD5ixIgR+wlGQt/CUDn1dx4WCTNi80DfQ33EeWJf8Lzr\nB1J9ZZ/0rDJHX0H9v6/R53mteevjLxsjoW9hpDFoRHka7Ic//OHkFa94xeTtb3/75Fe/+tXkj3/8\nY6sr10ZsDPT8pz/9afKe97xn8qIXvWjyqU99qp13jo4rGUfnf/vb3/ZIo17Xj/76178OXq8d/Tvf\n+U673x3ucIfJSSedNHnxi188eeELX9geDnniE584zUfSXCuprBceJT/44IPbo+Twy1/+cvKkJz1p\ncoUrXGHyuc99rgs9G/QUTunLDs7XMgmvXbvvve51r8md7nSnpg/58Y6SRz7yke3/T37yk5LK8iC/\nn/jEJyY///nP5/KidgLy/+Y3v3ny29/+dlrW3/3udzXo0jAS+hZH6sHvf/+//25EDm9605smN7/5\nzSdve9vbGqmM9bVx/PjHP27t/5JLLpn84Ac/aMRxn/vcZ/KHP/yhXa9k3JNSUJ/cGwrTP9knTP6f\nfPLJk9vc5jbtvz4I7n37299+ctZZZ+11QjcYGWSQJySvt7jFLSYf/OAHu9DDEGc1Qq/6gJSTtCce\nDzpoj2vw+c9/fnLYYYdNPvvZz06vbTb+8pe/tF/5OPzww1sdgDz0AzmkjL/+9a8nhx56aDO89jZG\nQt/iSAf40pe+NPnIRz4yPa8DXHDBBZOrXvWqU0ulJ5xeKpkMSR/+QJOXvvSljcTMfPQBRHTDG95w\ncu6557YOXMNW6CvCxtKMLlMnldCqvispOD7hhBOaNdqTGwseqb3zne+cDi4h/GUDocdCD9He4x73\nmHzyk5/sQu6JlDvvGKnniTJGH0HVW8Ayv/KVr7zHuYSRj+OOO65ZxjWdzUTu9aMf/ai1i8yE+3z2\n+Pa3vz35zW9+Mz1eVv56yNdI6FscSEa9HH300dNzKs55jf2tb33r9Nw86Qm8lz78gSbXuta12gzI\nf9B5H/OYx0yOOuqoKTFFQkhcAzq66XjVZaw4BMxV8bOf/ew/rvdW644dOyZ3uctd2v9qiTtG6N6o\nl4Fjb+Fud7tba3vyoDzubybxoQ99qA/6H6Cb3pJNWeOuqmUJWQauPeEJT2guHog+8itfDJocbzbk\nP20h1nrawawB1Xn9spYraewNuNdI6Fsc6uOiiy6anHbaadMOEsLQ0V/zmtcMNrBKQKOsLg94wAMm\n73//+5vFR7eZ8iMUb7GrYUPMwrHGWLJ8pj1c4zJB7OqslxA0QejIMgjBca+p53e84x3TOIGBgs//\nLW95y6BP+dJLL20+eQPVF7/4xf5yc+N94AMfaNcRkbIFynfnO9+5cUK9p0GHT3k1iPvd73532mZD\ndvQrjZ/+9Kd7kHG9NyBU+r/iFa/YjmPxZl3i3ve+d1tzAGX/whe+MHnDG97Qjr/yla+0/yFi2L17\ndyvnG9/4xslXv/rVaX3Jj/Jxs3FhmhXUGYh1K7Pj17/+9Xvo3z3oj0GlHr785S+3dvLe9763zabM\nqtMv/dLDt771rcn73ve+Fkb5QLnl07qEWaK8cftdeOGFLSw9SXdRmFGRkdC3GDS4NAiEoPGnMfl9\n9atfPTnkkEOaz663bqAnrFHmS7XIor8b3/jGzeUypM+QOiBuZMwaT505h3RCtD2Z93L3u9+9SQWS\nQvTIRLru69cim/q3aJrObsB/17ve1f4LwyVnDQABIgxkhWhCcoj+sssua/E//elPt4EnC3+xnrmA\n8ELuDYj64x//+L8zOAfa713vetc2kEjPfd3PuW9+85tT9xFU4q1oxFR86MHXv/71yTWvec3J1772\ntXaMrNsrYy8Pi7Dd88gjj2yECBaWd+3aNSXvxz72sU0/wcUXX9zKxbUiX9JVbvD/1FNPnZxyyilN\nJ3Rx/vnnN8LO4GIm5y2HdCktA81TnvKUKWm7r3aUgZBunvzkJ08+85nPtGN6N2DLv0EMubvXa1/7\n2smtb33r6YLrIhgJfRugWgbpWMcff3yzzhdFT0i9jPg3Mq1GBscee+zMRVF1gohiqVuoQ4o6H8vU\nf2SesNXlErdLFQPCMccc0yy0j33sY4101DGyTf2kY7MaLdTlWJ9lJd7kJjdpxwjvRje60R5uD4TC\nMnbOgMBdkUXF3//+95Nb3epW00V3YWKhWxRdj4UO9IDA/UrT/6wFJc0MIL3rhG5D6MjRDhe7gc45\n55z2y9UV0I/0hDXLog8DqvMs3Otf//qNNBGu+yHia1/72u26siN/11NX7qvsIWwf/cnsSXugZ4OT\nuO7rv8E1bUV+7QgCaTztaU+bnH322dPBNXlWR46Tf7uKpKN+Mhhc5SpXmf5fBCOhbwP0jV3jPuOM\nM9r53mc3Cz0h9TLi30CSiFgnZ4UFvb4ya6q6YwkiLZJOWIl/HqGLwxp3TR/0i3AR94c//OGWVtrB\nq171qhY+SPoIQVraB8suaQPrk2Uc8pR2yB4xGbxYmcIjPgSTRdH4z8W74x3v2Eg55ZjVflJ+1qhB\ngLh/UNvsEGGJh4+QtPTrFtDqxqkQNuVSBnX57ne/u+mlwvUMltxV1k8gA6Tr3/jGN6Z5RNAWreN6\ns7ZwxBFHNIMqO37oJ+G5begtMxt1yCUDdB2w5LnMUq/ce1xggXw4Z4Dv29+QzmEk9C0IFayT9n5N\njcEeV1aKxpdGngYxYmPQ7ll0D3nIQxr51H7QEzJCrx3L7/e///1GeHZg9HuP+/i9cLeEpJOm+kUe\n/PvJi3T109ve9rZtAOHLRWKsZrME7WLnzp2T293udi2dkGUlP/dj4bIGuQvEv9nNbtYsSYgbB+E4\nJ3x4AckbYDJY9OXoIb/iGKzMHBaF+4XQ4w6bRWIQCz15T1jkxnVm5kM/3DGI3H9+ede5lgLx+vUQ\nMwLus6QpP6x2u2zc0wzAbiSgf2kaBFJnV7va1aYLyZn9qFv1/ZKXvKTdzznWuMEyAxYOkL5zffn7\n42Ak9C2IdCBSp7t8awhd/aSjfvSjH22/qeBZFT1iMSCw2qHjXqikRb/qQKd0rAMaABADooyrAZnF\nIuuJrxdTfIOBdNOhgaWNkJxLWvzFXDrah05P/Hc/hMZCZ3FrO0P+V35hu6bStqQt70jK/xgKJ554\nYvukmfLGSs8uF/9jlVZir+0PYSJzi4HyroyZbYDws6A8OGlRQofqbxdf2fmmWei1TlMeYaxPXP3q\nV2/n6qCX/iXc4x73uDbgZpCOtS3/1rDu/1/3bw9BRSf0yEpPfq90pStN+NYd14HegGmwSH1f4xrX\nmIYDerWTzblFMRL6FkZIQwUjc9PHSvBcAwg9friR0NcPOrMI9Ytf/KJ11MyQ7JZARj0BCx9CyqJo\n3DDAGg2pJ/0qfXoIOtP6umCILLJ1Dyy8mgnYI8+NUvuqHRdIlBWKpPiFK+Ie8JDMQx/60ClpKasH\n1R7/+Mc3N1N86wYYgwOkTa22KJryKQPCysKlcvHzi083QwZLxVoJnQ6FrYMh0IEFVDt+IHW0srLS\nfN9mZOJZlwikYQdLgJzVTWA2kwEiLk9rEBkILWzaZgryfOaZZzafeq0r7cKmBrtr0mZY8nSbcHRg\nl888ffdYCqHPU/yIxRFiUek3uMENWqdnNfFHIhCdmjXIEukJY8TawK1Bv0jI7hBTbFZrdjf0BAzI\nKNsWWWo5h7x02JC6AaGvn/ikI1woSEG8pKUveuJQp0Y48hG3iF0rp59++jQcEsoiubR1au4UQDSI\n2kKvcHbI1Ocavve977Ww9n0j/bQnbhu7MdxXOxSXfvh5/Y+V63pfPhZrdoIkrHQRKr0yRmr8CvqY\nReiuKV/fxj3pKyydh1gzENv58uAHP3i69VFZLPZKQ9pmvXRZrXLrFIGBji7izmE1Z5eM9LlwGAPy\nLE0WvTjgXvKhv7LssyiK5OUrA5p4FqoZaJkpKIcyOZfyQ/RV9R2sSuh514SplzBGH34fvxZRTC/E\n48tLQ8/viPUjjUulGqHpuwq989OlcfcyYm3Qwaucd955rZ3rrOmovX5DZEgqLgnHIemhgSDx02kR\nkH6FuBGqvcis2toP5QWR23aIuGLBG8xf97rXNbdCdqhASAOBIG/tx95mhBYCMSDov8hMmkjHbMQi\noXzq01V2797d9IEstD3pQsrdl7MXZYlo09p3CD26AGEdu0cV+QLXMrgAkjUjsQ2zStKKGCTxmK2d\niLSHeqBLEl+/wdVzAOLJQ7YymgmtXG7hW9Ak/oP7mNF4sEd90W1m2K5xlSmHulLHcdFw07Hoq6hb\nejeg6ufcVsJFf7Ut1f4+l9CTEbAQZwRxTibSWE09WDfiOp/GP2L96PVHp6mHioSrFdtX8Ij1I2QV\n9Dper4RkKtQxcgpRxV9et+f1QOzC+a2Pmgcs4liI7hv4r1xxFwzB+ZBtCDcWKkQvrslzT+DzJKSc\ntGseop8e0Uvi1LWBunMkqHpOetUarnC91jO9xMrPb4Ww8k/vRJjEN1BV/oQMZIHwtb76/ASZKQXy\nKW5015cPZhJ6FJiEjFAIfQgU+spXvnJm4xixHNSG08uI1dETbLUiK2LA9DperwTSrEQS6LTIM5Z2\nRY0/RET9udrZc60vX0+qQ8j16AliffbkspqIL04MwOi85jVh6oASshSu6iHhU7YquWdmNanHISRO\noA7ETflm6Uh6GSAhA07yFODJlCekXPMy1EaC6KvqrOo0mEvoIucGAlmtdb5mHIQzHasJj9gYaqWm\nIUdSJxl0a0OY1SBGDCP6SoetnTrtu4bbTAH3imVOch5iXc8igKCmBRZ2K9JnQwghgT69mi/3qxI/\ndqzhWJjp85VcVpMQXchNuslbkONIfYgq7T5lWMTtAzVehfvHDUQyE+GmEZY+U27X3KsOttUFlDLk\nN2lJJzrMsTjKlTQrEi+u1x7S6csHMwm9R32VZW5uNTwZq++SqA1jHsQdutcQUun1uEpQpz9rQZ/e\nvpSap9WwqP62O+oUW0frddZL1cuQjmonGNraVxFrqL/HeiUYOs69Qhr6Vvok8V8br+SfQb6m05PW\nMiAP0ctakPzVwbNHdEASjj6in4Sp6PUcid6G4gTOZ4DJ/aLjobrvIXzym3TCjX5TnuQnA3jKUyXp\nJN3kOfGDofwsTOgc9bZCSVRGjCAeT04BKqpyhgrvXDI9S8FDSL6irEiQe9X7LypR8FaQmqdaibWB\n5rxGXvXZd4JFpY+/ryT5SSfq4Vwafa+3KgELZ8h1AX36fcdKGHVR87ZRSdlyHPjvXjm/KKHLW/JY\n/1f0Za2QrvBpX7N0n34VyMOssPOQe/Tlr0gdV71vZUKv12r7qeWr8eaVfegejofqtA+7MKHHQrcn\n0+q49xnYrgV1sWStsIvGKr77zxNhrF5bJDLd65W8UdS09rXUPK2GobraHxFdIDOPZdtNME/sDtCe\nbR+zQ2AoraAOnlVCOiHQdPiNSkgqxzUf7lUJbCT0rUHovextRM/R26w8LEzotuLknQfAp4TkK2rF\n6nS2Q8Xf3qNaUbMyV5E8qdTa+CKBx6G9xcyb6tYiHgXeKlLzZEuWLaEeXfZL7O/NeW4vv46rCLMW\n6ePva6lI514r6o6DCu0lbhbt00NbvT4Ivdr6lzrp87hekbZ0c2ybnCdN/XcvW9qIY+HkI+dS/87r\nYwYr/5VBWyDav1/npS18n/+Uz2/i1nbXh48epC1Nx+lnSW9REb72OW2bSDPt3HX5IgmnbydvKVP0\nk3SHRBzlSxy/iZc6dj76y/2UL/H9t4U1IlzSTx5zHD1GZ35T38lr7pG8VEk6dJHrnkVJW66++B4L\nE7pdLvl6iA7GKs87mkE8N7F30z5NT4Qp+GZh3qgU6Jz288prv69zNWHVKb+4nuqyyJvzFJR9qHtL\n3Ncg6te+aHnLHml5yXn7XZO3aqH2+3hXkxqXxMI1KzI7khfHZmd+I/3+7b4c65UKdR+Lea0Yavix\n2gJl7O9PUj71vx6dzhJppx6JdkavZr/+p75dy3/Xq+6dT/vIcZ//XEu8Wk/1vHDKmHg1jzWfwjtO\nHvM8RA27iLhn0lCGGj/9seY3ZZbHWn75zvXke0jEk9foJPdLWpFa7yRlzv/0jaSROqk6q/mIbmv6\nKXfSmZeP6Ns5bWOIl3usm9CFY+XUqV9FJfSh6/FrsuLjxpkn2dxvtOr33KaDEqRO6hR0NclgEcsf\nsmUJ1mMdbhTJzxCJZeoFVf+ZDmZ6thapcYfuCbnP3oR71vao3bBm+07biw6sM/jvUfmKWo6knzbQ\n68D1tKWE26ikfnLcI/lzbZbOnY+bKMd9/vt2W+u7QjhlTLyaxz6fies37qEadhEJ/K9um3ot1+u5\n6u5xvvbX5HtI4qaKTnK/HrXeodaN/5Uzariqs5oPqHWQOMl7zX9FzUeuJ/wsj0cwk9D7SugJPcgN\nci6W+mqEnnh2LPhCyMUXXzxXTDe92IcPvd6/ohZ+I5C+dzx4VDqLjvsCi9y3NrrNgvLXxua/FzIN\nfRVn2ZAX+ci7Mxx7J4gp8GqiXfk6TN8epBeXSwbuvr1X3YtfO+xGJWnneBbmXYPe+Orzv2jbCFkl\nXs0jzMrnen3oFeGLRdDXY1/2Xs8R8WL4hNuG0Nd7LbP/dZCo4arOaj6gz2NQSb9Hn48e83ZlbZjQ\neyVnv+aihL4eDDWuCp1UOdYi8ekrD7+V9zF4dSnMUvwysUjjA3mv51ZrDLPQ13fS9TIoHw3woqa8\nq7l2ltrIQwwbldr++rp2Thj1ldnYkGQGOKQL5/Lgx9D1HsLVDrtRCfrjHvOuAT30+qmYd60i9Rj0\n952Vz7WQ8Swow6Lo+2Ffvl7PEfHSnvs489DXVW33PfqwOR4KC7PSmYW059X0NZPQAy8f4kP1Qh0v\nhfKSG/7VoUquGfS6yby1rb5cZ5ZsNvoKWKusrKy0Qammt8z8Qga5ZaW/EXjJFJ3UAWSZiA6WoYu+\nLtdzj+hBB7NgZTbgQwQXXz6bNJP0aweXtiRM6jaL+mlnG83HLBiIvUfbelC+3+ntjBbr8jUd+XDP\nRfOR8wk/Dxb/soBJF5kxea9MjKdZ20k3CvnrjQvHuW8/MEDKnXqpi+b1+lbHXEKPYgL/FVAY13pQ\nGOtYwZGhd0lHmT1hLtKANoJaOeuRlb1M6Bp3OvtWxN4m9GAZuu7rcj33qH3Ek4RmL7b13ve+953u\ngvAipl27drX1nzwMJXzikY3mYxa4pbzMy+s6Um9cZt7/7b3bsFZCrzvTVoNZLpelZ1fogH6QuZ0q\nj3jEI9rsl7G4zPYeN4uBdseOHXt883UWXLexggHbz1pm6WUrYSahV5eI49V8ybWxghd25SOt+4rQ\nq/T3X01W9jKhb3XsK0JfFjajPrUT0L4ZMr44ow9B9pCDWa33jVfdLbsfSBtZese2AaaSU33iO31j\ntXzk3eqLEnBcr179i2B6V5jdWbZB1zdAbjY2QugPfOADm5Uuz1U/Wx1zCT2WOKkv3R96v0AWSEzr\nLKBRoobEStguhF7DruwjQvcRi62IntD3lj6Whc3IfyVJbcaHh21F87/C+6ytP7FOg77N1XysNz+B\n+MmD9y+ZLag355EnkoXav/u89KjrSX355sHHOXCLe4XUgVvKwOL1tJsN+ZPPjbhcLMJX8p+ll62G\nmYTeoxY2Fdo3xr5RrEWWgf4es0R5+zJzF4XQ+4Y/VM7NgAZnq91mpbcZSF6siXjYYVbdH4io5UZU\niFIfUo/V6PGObeRFfxBimbVboW+LeXlX4H8WhRPW/1i6dUbtvnzY6dfixUKv7Xq1OuwJfbX6D3G7\nl28p9O4aujAAckeFOPNhjwr3Ui7lSbjott437bK6LXs9BuIJL+ysMMl/rtdwGSxyf/9nWf7zri0D\n6yb0vkJzvT+3qCwD/T3mSQ+Wso/91relzSv/ZmCrEHo6UW0HFsTpJGSxTD1sR6g7hK7+6CeEoP0g\nw4c97GF7hKc77gYfL/C1G75tH17IO7Bd95Ui/uaXv/zlzQ1gYEhcYWzJVCc+iuHD1lwKNX2IhV4x\n6zXY87BRQu+hvIceeuj0CUgfrLaTii58NMLDXnbWZSDgb0dUykpn4qdvur/nUx796Ee35w98uYln\nQBumw4c//OHt26wrl88wE96DgxdccEH7MpH/XEB0b/A77bTT2heKIGtbeFE9qCM6t1FE2pn5+JiF\nL17d7373a/rmpZB/n/rrPxi+TGwqoW9Elo3+fr2kAwCrwbZFFeLJLotJBxKhV/hyis5FDzqmNqKj\nLFMP2xF0gbyQikfjzfDo6txzz20kBXXnhOcp+NXrTo8zzjijfUkItLnrXve6U9+19LVLRAZ2kLgX\n1wC9c28ec8wx07TShw0ydpikbvzy9ef/olgroYeI6SSfzWOBywtC5MLz6oL0O7pRnh07drTz3FS7\ndu1q13wij64gs4yjjjqquXeBK8vnGAM6fdCDHtRIPsfyEZeX+xscK88hwYSly8xi4kM/9dRTpx8M\nTzifDEz94E2DiXzJf6xynzM8//zzp/GWjZHQ/0/SsZQ/frfEg61A6Gn8/e8yUBeq5Kcep5EvSw+b\nlc7ehLpDlD4zFti/z1UVy7t+WYeVibDyYBOxE8S3TAG5sc4rQvjaKnLxcrzqykBC/YvIWOhItGKz\nLfT+mITQ5AnR2eGS96HYyggJk77HaLC7JPVPN+7H6vU0eeC6NL14TRpmjwa7wGDpHKsepOND0TZp\naLt4bufOnXvMovLZOaBD+U6bv+iiiybHHnts+1/dJz4lZxaf/DICfUA6dSLv7uX1BnsLCxF6X1nL\nkM2GRRdTN++b8etbgjqYaaqKIBdeeGETX/gm+Taj6ZpR3LFf1xI2Ij0NxHXb04SVvs7r13mSafBQ\neX2QNy8cMk1buXxKaHrIOumfemQpp4HFLxcikJ/cL6LjK4e8y1PKuBaJbqSnvMpoEcs5/6uYctK5\nsHTYX19N5NU9dIa+/W0HqBMkYFEU1A+xpdF5dZ36U2cnnXRS2/2irhGcPdp0wDWDaHw0Omk5DknU\nviI9RER/rFHkrQ2FIIVloTuXeH6HLPSQMveAHR4IvIoy+PAzt4i83/Oe92wDCoKWt57UU4fiIZgY\nH5ndDSGvbYCUl79cGlwtXoLF905nSDIDnjLGepY2vRs84+qgP2nYqAEGV3k/+OCD2wDC3RNLWxy6\njIUOBo+sp6Vs7qHvHnLIIe28eyindNM/1YNzntvZW5hJ6D0BLVs2G/E58pMRpObY9NfHcHOOICmC\nlJxH0AjRsV/XEjYiXNJHYMJ6KZkpsTg+ouvYNFMDCvlG6Fk+6JywMFgoJ554YrPeUjER+4rTSTSY\nWBd+3SflJCmL9JPH5HktEj3Rh/SQde7V6yMDpMFT+P76apL8wqwOv5WhDVdCr3UVK7USuo6vXrUD\ncXMtFiCLUJ8c+l4msuN/Zx3yAWcHmh0lWXgFeXCOXzg69Tv0xDdIN3mpM1XCReIakqq+68Tr2zep\nOsm9FiV0EC76i9uoDm7AYHJdGSH9IsiahDIznFyPrg2i+t5Nb3rT1u9AuT2QJc2U86yzzmo+dfEy\nQwEDcYjfPfRfM4NgS1noPeEuW5YB6aZj1UagQmoZK2Y1tprXNDS/9FW3dPbQAfonZdPYk7c0QudS\n+a5FYu31SB781vQTr6JeX1SSzwp57c9VpLMcaKCTSuhVR87r6Gl3dPioRz2qLb7VcMgnfmHWOyIR\nJ753bQCBaVPi8s8Hub8HeliysBZCT73NqluEPoR5ZJ48Iencay2Enn5h4LJwCckfss0HtPmtuSoh\n/US4yy67bKo7s5dY6PpYP1CaeZi9A0Jn9Wemwwj0/Yd8DjDwHWUWfmChVF4r8q2HvYX9ltA1Yot5\nrF1+TWXT2JUtVkeIrzbCSkjJVzpilTQ2+mIVucell17apmx5paa0kHlt4H15k55zGpBRPo0+Mg/u\nLy951WhEx2CR6HC91bJemJYq4xCylYxraD2IrrYbUj/qrxJ6vc4C5FtVz+qDZWjh7Mgjj2zGQG1P\n3Flg2u8py6oTZG6GRFe3vOUtmxsHhGHBegKUG9DsENZC6BVDuzLyMZsh1D5U+1J0Ugk9/DKESujC\nh1CVjZsnRpk07DDRV4Sxq+X444/fI928XC/3zXMA9I3Q+eTpMVa4ATbbJtWPfLuOxA0Mhx9+eHOf\n1X6PzLl/nHcfHFNdM+Lri/13I5aJmYQ+q4JmyVYDZfKr7dixY0rSLBcr094zASo3FRqEYIOefCs5\nakzRjUrLy8g0vL7TrKarNFaDAQzpvSLHGQyIaSFffOqP+8OiXD87iWis9RpEVzmfTgVcInYP0IHd\nFbVxR4/Xu971potRyZew8lTJyX36e0unP7dVkfIql4Hz7LPPbiRwwgknNMLwil9lFw6xxB3iraEr\nKytN/9rLzp0724KhemMUIFN6EJeL6/7/df9GGtYn9NFYpdxbrGbxXLf+4B0twnPDeGVw8nTmmWe2\njyXoD6x+56S1lu8VVEKF2i77dkq45SwS2prIncGlaLeKNNR9354Rn106xH9tpfY1ZfTJS32YPpWx\ngu4sKLOuXbfA7B7IVt/0xOyuXbtamZH5Oeec09yj3CYs7SyqqhsL0nRk0XX37t3tvIVSujWgGiCt\ndakTHKIfScvWyCOOOKKlrV0YcOzOMXBrE8tu28rrPmS/I3SgeFMpUCYNicXutQRDUDkILOXRqEJw\nKq0eQ8LR2UYJHYRl4VULfZaeh84j77qjQT5YFvSgcyQvFTXNWCQZ0DJd7TugdDIzCKIXOhTWvevA\nWPVGx/3AMU8vWx30oEwkU/noWzm1G7MbayuIvodZT91lQRd1wGOtZ2CtVqr/Zp1Z0BtC9DzLKl4U\nXEbypUzViJglcU0IK5/1eY7Er0iZievik7TZDHIGz/qR8H72yXIPxEm9mN2kPVuPAoOnQa43NPpZ\nRPIqPuNEP1eenI+O0y9qOVL+vrzLgHvst4SuEo3qWaRQ8YRVY0QOlNWCHmvWwwDCqAAVx1pmPbGG\nUkbHrAALf2lsflcj9EWgEdgiJf4svQf9eUSqbPETqkfkwkLKThpWDeJALH6FES+7drLljU58eISV\nZQdFLG6Wk8VLOtK4TfmRjQVoD4jQjTCsUPoXzo4febLw6V7KRE+mhaxNcVhXcU1BnRVsN1QiUB51\nGTJKPUHKmHqGkGAPuqHvxAnhpT3knkk7g2klmqF4a0HaQEixb3+9QF+PdUZbJeeCer4aDnU23esq\nnJV0hgyY6CO/CL22u5qmdDIY9OSe+7hGH5l1VLgeUq95quXcbEh7vyV05UBitn/lyS0LTX5BZQhj\nEYPfV2cw7UJAGo5pkukaHHfccW0Ky7dmWxn9ILpMDVXqRgldOA2g6npI78HQ+VNOOaWRq9e2+jVF\nTXkge3dNW+XdeS4oZTCAcacgcuU0faWjSy65pPlP/Ve++AilxVJSVtNbpE2H0jAjcJ4/1BQVWJGe\nZkTirsmrJ+/AgJIFwL5jbAeEqKAnDXAtVmBfPte0p0p2dcFOHaX+tNeh9pQ+WhESTNvo77uePlvv\n0be/XlKeSurVsq6SgSblqHmX7+iu5jn/67kQcq+LDELgWsKFbKuFHl1ndwyEmHO9Hyxiked/TQ/E\nrbPdfjDaLMjvfkvosLKy0shI/jM95dNSPpWCpI8++ujpAw/2utozyoK3g8DWsJQ/FhKS54P3kIdH\nfdMQkVe2jDnOdqbaGOfpy7k0sCFZDcLIDws/x1XkXR3b66wsym/13uteDXimnnytZjXScSxM3FBg\ngOTWAVY+n6GBIS4BFg/dIXQ6yEfF00H5eFnqYOakPtRLFr1gkbIeKFhL/W8lJM89hwxxyTwkjWWg\n7x/zpM9zL/ptJGXskXRC/n0aGxWQPkOL7HeErhwWPBA6Us0Ii2jzHmaLGieffPIe8ZAPS50+lDvx\n/CIqD1fs3r27uQqQUkZc7hnXAQlaBAuQ3Wr6cm6enleDfCvryuWDGAzFR77cL7EIHXuoIn7ZpINc\nk46yZUqJeC1wOcei56/0WLNBMa9K1pgQNRx22GGtTBkQvDqAe0V8ejd4gIHCPZPPDAAHOvr62y5I\nnnsOGeKTeVjt+kbQ94/Nkllwbaj8myUg3f2W0IEljThCymCRMFYsvy8rk8WaKROitkh1netcp5U7\n6SAvjyAjNenlsW5uA8emOVwVQSz0YDV99dd7WQ1IUFlY1kP1BVb3uUeU1aCj/FbuQRnsgSbcNbt2\n7ZqmnfdeIGq7OKTPtWJrGCi38kvXb/TLbVN1YoE6O4z4+/NujZXLBw+6lM/ofMT2Rt/+ZvHJPKx2\nfSPo87dZMgt9uM0W2K8J3YKdbVN8tcoFSI+rgC+Xpcify9JEdMLbA8zPJxxi5EZh5Vs0Bb5p+1UR\nkYcQPDQgrkVS57lhWO8s/B07drR4dLOohT5PVoO88O/bMiV/fXxrB66ffvrp0/djg//yi1Tt582C\nrL3M9GHx1yInndjO5SVFWdS0kMq6FsYuAoMdEuend08vmDJz4SP3TIB42hZ/uz28fPx0Q3fixR3U\n+3tHbD/07W8Wn8zDatc3gj5/myWz0IfbbIH9mtBHbC7WSrJjmxjRc8Q8ORCw7PJKd79eFB0xYsS+\nQ88R8+RAwLLLK92R0EeMGLF09HzRy4iNgx6nhI7MR0IfMWLEMtDzRS8jNg563IPQLaxli1ovSH5I\nct1AkC1uo4yyUUl7WlT6+GuVPr29LX1/669vN+n1a1F9nvThe+nT7/W1mvTx+/S3u+BiGwpsVvB6\nk4P88WDNiBEjRozYnvBgpOc9GqHn239cLOtFP5UaZZT1yFrRx1+rjNhc9PrtXbi99OF72Wz06W93\nAXrkZbFVuBE6cUC4YOr7teNj7yXXLaqSvNN4lFE2ImlPi0off63Sp7e3pfa12p+2q/T69RbRedKH\n76VPv9fXatLH79Pf7sIqx9vcLUj9oEWUOsooo4wyytaX/wVHdpMzbTxGjgAAAABJRU5ErkJggg==\n"
    }
   },
   "cell_type": "markdown",
   "id": "42ddf6e5-957d-4d67-804a-ee54c210e569",
   "metadata": {},
   "source": [
    "![f1score-formula.png](attachment:b4f4967e-9461-431b-aa93-9bdd4a20e8a0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf78816-2f59-46de-bbfc-92b1c97f01e3",
   "metadata": {},
   "source": [
    "Recall과 Precision이 둘 다 높아야 되기 때문에 둘을 평균 낸 것은 알겠다. 그런데 굳이 조화평균을 쓰는 이유가 있을까? 아래 그림처럼 예를 들어보자. Recall과 Precision이 각각 0.6, 0.8인 경우와 각각 0.7, 0.7인 경우, 두 케이스의 조화평균을 구하면 아래 그림과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9599694f-511c-4d45-bfe5-73814f33f9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "조화평균 : 0.69\n"
     ]
    }
   ],
   "source": [
    "recall = 0.6\n",
    "precision = 0.8\n",
    "f1 = (2 * recall * precision) / (recall + precision)\n",
    "print(f\"조화평균 : {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b4057c-52fb-4466-8544-5ce849dacf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "조화평균 : 0.70\n"
     ]
    }
   ],
   "source": [
    "recall = 0.7\n",
    "precision = 0.7\n",
    "f1 = (2 * recall * precision) / (recall + precision)\n",
    "print(f\"조화평균 : {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741cfe34-e879-4b2d-8f19-62a7c3b38dad",
   "metadata": {},
   "source": [
    "두 케이스 모두 산술 평균은 0.7로 똑같을 것이다. 그러나 모델을 사용하는 입장에서 진짜로 원하는 성능은 둘 다 높은 것 이외에도, Recall과 Precision 어느 한 쪽에 치우치지 않아야 한다는 것이다. 조화 평균은 두 숫자 간의 차이가 적을 때, 더 높게 계산된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0309f06d-0e5a-4616-898a-78e9c380ac54",
   "metadata": {},
   "source": [
    "즉 F1-Score는 Recall과 Precision 사이의 차이가 적을 때, 그리고 Recall과 Precision 둘 다 높을 때 더 좋은 모델이라 판단한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0e663-7ce0-43d9-8543-ffc5e6e7aa1d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c8d031d-6360-4c79-9414-a5c17e582e8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "133eb633-a500-4f42-8a7d-c24e480d8612",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12cbc94b-c50f-4448-87b3-d64e0df72fa6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b8f27b5-fb8b-49e5-8950-3dbefa7affdc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47de5a7-9996-4167-80b5-2336d5b8f66d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cf15932-fea7-4738-9ced-660f2393edcc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f4c3ffc-c9e6-45fd-83a7-afdb1b717527",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e7d7878-e38b-4732-99af-38ec1c2e145a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b103f14b-2335-4d30-b56e-bac6d0c9462b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterbook",
   "language": "python",
   "name": "jupyterbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
